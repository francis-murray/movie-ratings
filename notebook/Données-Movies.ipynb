{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sklearn.feature_extraction.text as txt\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model as lin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import copy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['french','english']\n",
    "stop_words = []\n",
    "for l in languages:\n",
    "    for w in stopwords.words(l):\n",
    "        stop_words.append(w)\n",
    "# Prend une phrase en français et rend la stemmatisation de la phrase\n",
    "def convertF(words) :\n",
    "    stemmer = FrenchStemmer()\n",
    "    current_words = list()\n",
    "    for i in words.split() :\n",
    "        updated_word = stemmer.stem(i)\n",
    "        current_words.append(updated_word)\n",
    "    return \" \".join(current_words)\n",
    "\n",
    "# Prend une phrase en français et rend la phrase sans les stops words\n",
    "def deleteStopWords(words):\n",
    "    current_words = list()\n",
    "    for i in words.split() :\n",
    "        if i in stop_words:\n",
    "            continue\n",
    "        current_words.append(i)\n",
    "    return \" \".join(current_words)\n",
    "# Prend une phrase en anglais et rend la stemmatisation de la phrase\n",
    "def convertE(words) :\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    current_words = list()\n",
    "    for i in words.split() :\n",
    "        updated_word = stemmer.stem(i)\n",
    "        current_words.append(updated_word)\n",
    "    return \" \".join(current_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/movies1000/pos/\"\n",
    "# va contenir les données de movies sans la stemmatisation\n",
    "alltxtsMovies = [] # init vide\n",
    "# va contenir les données de movies avec la stemmatisation\n",
    "alltxtsMoviesStem = []\n",
    "# va contenir les données de movies sans la stemmatisation sans stop words\n",
    "alltxtsMoviesStop = [] # init vide\n",
    "# va contenir les données de movies avec la stemmatisation sans stop words\n",
    "alltxtsMoviesStemStop = []\n",
    "labsMovies = []\n",
    "for cl in os.listdir(path): # parcours des fichiers d'un répertoire\n",
    "    alltxtsMovies.append(open(path+cl, \"r\").read())\n",
    "    alltxtsMoviesStem.append(convertE(open(path+cl, \"r\").read()))\n",
    "    alltxtsMoviesStop.append(deleteStopWords(open(path+cl, \"r\").read()))\n",
    "    alltxtsMoviesStemStop.append(convertE(deleteStopWords(open(path+cl, \"r\").read())))\n",
    "    labsMovies.append(1)\n",
    "path = \"data/movies1000/neg/\"\n",
    "for cl in os.listdir(path): # parcours des fichiers d'un répertoire\n",
    "    alltxtsMovies.append(open(path+cl, \"r\").read())\n",
    "    alltxtsMoviesStem.append(convertE(open(path+cl, \"r\").read()))\n",
    "    alltxtsMoviesStop.append(deleteStopWords(open(path+cl, \"r\").read()))\n",
    "    alltxtsMoviesStemStop.append(convertE(deleteStopWords(open(path+cl, \"r\").read())))\n",
    "    labsMovies.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxtsMovies=pd.DataFrame(alltxtsMovies)\n",
    "alltxtsMoviesStem=pd.DataFrame(alltxtsMoviesStem)\n",
    "alltxtsMoviesStop=pd.DataFrame(alltxtsMoviesStop)\n",
    "alltxtsMoviesStemStop=pd.DataFrame(alltxtsMoviesStemStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxtsMovies.rename(columns={0:'Reviews'}, inplace=True)\n",
    "alltxtsMoviesStem.rename(columns={0:'Reviews'}, inplace=True)\n",
    "alltxtsMoviesStop.rename(columns={0:'Reviews'}, inplace=True)\n",
    "alltxtsMoviesStemStop.rename(columns={0:'Reviews'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
    "for doc in alltxtsMovies['Reviews'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        try:\n",
    "            word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectorsStem = pd.DataFrame() # creating empty final dataframe\n",
    "for doc in alltxtsMoviesStem['Reviews'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        try:\n",
    "            word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectorsStem = docs_vectorsStem.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectorsStop = pd.DataFrame() # creating empty final dataframe\n",
    "for doc in alltxtsMoviesStop['Reviews'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        try:\n",
    "            word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectorsStop = docs_vectorsStop.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectorsStemStop = pd.DataFrame() # creating empty final dataframe\n",
    "for doc in alltxtsMoviesStemStop['Reviews'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        try:\n",
    "            word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectorsStemStop = docs_vectorsStemStop.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectors, labsMovies, test_size=0.2)\n",
    "model =  svm.LinearSVC(max_iter=150000)\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectorsStop, labsMovies, test_size=0.2)\n",
    "model =  svm.LinearSVC(max_iter=10000,class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectorsStem, labsMovies, test_size=0.4, random_state=1)\n",
    "\n",
    "model =  svm.LinearSVC(max_iter=150000)\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectorsStemStop, labsMovies, test_size=0.4, random_state=1)\n",
    "model =  svm.LinearSVC(max_iter=150000)\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('classifier',\n",
       "   LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "             intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "             multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "             verbose=0))],\n",
       " 'verbose': False,\n",
       " 'classifier': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': True,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__loss': 'squared_hinge',\n",
       " 'classifier__max_iter': 1000,\n",
       " 'classifier__multi_class': 'ovr',\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('classifier',  svm.LinearSVC())\n",
    "])\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sidhoum/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('classifier',\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'classifier__C': [1.0, 0.8, 0.7],\n",
       "                         'classifier__class_weight': [None, 'balanced'],\n",
       "                         'classifier__dual': [False],\n",
       "                         'classifier__max_iter': [2000, 1000, 6000, 9000],\n",
       "                         'classifier__penalty': ['l2', 'l1']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {\n",
    "'classifier__C': [1.0,0.8, 0.7],\n",
    " 'classifier__class_weight': [None, 'balanced'],\n",
    " 'classifier__dual': [False],\n",
    " 'classifier__max_iter': [2000,1000,6000,9000],\n",
    " 'classifier__penalty': ['l2','l1']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=grid, scoring='accuracy', n_jobs=1, cv=5)\n",
    "grid_search.fit(X=docs_vectorsStop, y=labsMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "0.8435\n",
      "{'classifier__C': 1.0, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__max_iter': 2000, 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------\")\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectorsStop, labsMovies, test_size=0.2)\n",
    "model =  svm.LinearSVC(max_iter=20000,class_weight=\"balanced\",penalty= 'l2',dual= False)\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25001\n"
     ]
    }
   ],
   "source": [
    "alltxtsMoviesTest = []\n",
    "fname_test=\"data/testSentiment.txt\"\n",
    "s=codecs.open(fname_test, 'r','utf-8') # pour régler le codage\n",
    "#generation du bow du fichier test\n",
    "file =open(fname_test, \"r\").read()\n",
    "alltxtsMoviesTest =file.split(\"\\n\")\n",
    "print(len(alltxtsMoviesTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxtsMoviesTestStop =[]\n",
    "for i in alltxtsMoviesTest:\n",
    "    alltxtsMoviesTestStop.append(deleteStopWords(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25001\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxtsMoviesTestStop))\n",
    "alltxtsMoviesTestStop=pd.DataFrame(alltxtsMoviesTestStop)\n",
    "\n",
    "alltxtsMoviesTestStop.rename(columns={0:'Reviews'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectorsTestStop = pd.DataFrame() # creating empty final dataframe\n",
    "for doc in alltxtsMoviesTestStop['Reviews'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        try:\n",
    "            word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectorsTestStop = docs_vectorsTestStop.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectorsTestStop= docs_vectorsTestStop.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  svm.LinearSVC(max_iter=20000,class_weight=\"balanced\",penalty= 'l2',dual= False)\n",
    "model.fit(docs_vectorsStop, labsMovies)\n",
    "resultMovies = model.predict(docs_vectorsTestStop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(resultMovies)\n",
    "plt.title(\"Histogram labs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fichier = open(\"predictionMovies.txt\", \"a\")\n",
    "for i in range(len(resultMovies)):\n",
    "    fichier.write(str(resultMovies[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectorsStop, labsMovies, test_size=0.2)\n",
    "model =  GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
